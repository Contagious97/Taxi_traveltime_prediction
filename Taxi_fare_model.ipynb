{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ## Laboration 3 - Travel Time Service\n",
    "Made by: Robin Jamsahar, Mohamed Osman\n",
    "TIDAA3 - KTH\n",
    "2022-06-10"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#pip install fastparquet\n",
    "#pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import all the necessary packages\n",
    "import pyarrow.parquet as pq # for reading parquet files\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read.parquet)\n",
    "from pathlib import Path # to manipulate paths\n",
    "import datetime as dt # for datetime objects"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ## Cleaning the data\n",
    "Here we clean the data. We have a data parameter that is a dataframe, and a type indicating the type of file it was(Either green or yellow datafile)\n",
    "then we set a few rules for what is a good data point. Lastly we return a cleaned dataframe."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "outputs": [],
   "source": [
    "def clean_data(df,type):\n",
    "    # print(\"Cleaning\"f\"{df}\", \"with the type\", type)\n",
    "    # type == 1 is yellow data\n",
    "    if type == 1:\n",
    "        df = df[df.get(\"fare_amount\")>2.5] # filter out the data that is less than 2.5$. 2.5$ is the minimum fare for a taxi\n",
    "        df = df[['tpep_pickup_datetime','tpep_dropoff_datetime','trip_distance','PULocationID','DOLocationID']] # only keep the columns we need\n",
    "\n",
    "        df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime']) # convert to datetime\n",
    "        df['tpep_dropoff_datetime'] = pd.to_datetime(df['tpep_dropoff_datetime']) # convert to datetime\n",
    "\n",
    "        df = df.drop(df[df['tpep_pickup_datetime'] >= df['tpep_dropoff_datetime']].index) #drop rows where pickup time is after dropoff time\n",
    "        df['trip_time'] = (df['tpep_dropoff_datetime']-df['tpep_pickup_datetime']).dt.total_seconds() #calculate trip time\n",
    "\n",
    "        df['tpep_pickup_datetime'] = (df['tpep_pickup_datetime']-df['tpep_pickup_datetime'].dt.normalize()).dt.total_seconds() #normalize() makes it so that the time is in seconds since midnight\n",
    "        df['tpep_dropoff_datetime'] = (df['tpep_dropoff_datetime']-df['tpep_dropoff_datetime'].dt.normalize()).dt.total_seconds()  #normalize() makes it so that the time is in seconds since midnight\n",
    "        df.rename(columns = {'tpep_pickup_datetime':'pickup_time','tpep_dropoff_datetime':'dropoff_time'},inplace = True) #rename columns\n",
    "\n",
    "        df = df[(df.PULocationID < 264) & (df.PULocationID > 0)] #only keep locations within the city\n",
    "        df = df[(df.DOLocationID < 264) & (df.DOLocationID > 0)]\n",
    "        df = df[df.trip_time != 0] #remove trips that are 0 seconds\n",
    "        df = df[df.trip_time < 20000] #remove trips that are longer than 5 and a half hours\n",
    "        df = df[df.trip_distance != 0.0] #remove trips that are 0 miles\n",
    "        df.info() #print out some info about the dataframe\n",
    "        df.describe()\n",
    "\n",
    "    # type == 2 is green data\n",
    "    if type == 2:\n",
    "        df = df[df.get(\"fare_amount\")>2.5] # remove rows with fare_amount < 2.5$. 2.5$ is the minimum fare for a taxi\n",
    "        df = df[['lpep_pickup_datetime','lpep_dropoff_datetime','trip_distance','PULocationID','DOLocationID']] # remove columns that are not needed\n",
    "        df['lpep_pickup_datetime'] = pd.to_datetime(df['lpep_pickup_datetime']) # convert to datetime\n",
    "        df['lpep_dropoff_datetime'] = pd.to_datetime(df['lpep_dropoff_datetime']) # convert to datetime\n",
    "\n",
    "        df = df.drop(df[df['lpep_pickup_datetime'] >= df['lpep_dropoff_datetime']].index) #drop rows where pickup time is after dropoff time\n",
    "        df['trip_time'] = (df['lpep_dropoff_datetime']-df['lpep_pickup_datetime']).dt.total_seconds() #calculate trip time\n",
    "\n",
    "        df['lpep_pickup_datetime'] = (df['lpep_pickup_datetime']-df['lpep_pickup_datetime'].dt.normalize()).dt.total_seconds() #normalize() makes it so that the time is in seconds since midnight\n",
    "        df['lpep_dropoff_datetime'] = (df['lpep_dropoff_datetime']-df['lpep_dropoff_datetime'].dt.normalize()).dt.total_seconds() #normalize() makes it so that the time is in seconds since midnight\n",
    "        df.rename(columns = {'lpep_pickup_datetime':'pickup_time','lpep_dropoff_datetime':'dropoff_time'},inplace = True) # rename columns\n",
    "\n",
    "        df = df[(df.PULocationID < 264) & (df.PULocationID > 0)] #only keep locations within the city\n",
    "        df = df[(df.DOLocationID < 264) & (df.DOLocationID > 0)]\n",
    "        df = df[df.trip_time != 0] #remove trips that are 0 seconds\n",
    "        df = df[df.trip_time < 20000] #remove trips that are longer than 5 and a half hours\n",
    "        df = df[df.trip_distance != 0.0] #remove trips that are 0 miles\n",
    "        df.info() #print out some info about the dataframe\n",
    "        df.describe() #print out some info about the dataframe\n",
    "    return df #return the cleaned dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "outputs": [],
   "source": [
    "def missing_cols(df): #function to check for missing columns\n",
    "    '''prints out columns with its amount of missing values'''\n",
    "    total = 0\n",
    "    for col in df.columns: #for each column in the dataframe\n",
    "        missing_vals = df[col].isnull().sum() #find the amount of missing values in that column\n",
    "        total += missing_vals #add the amount of missing values to the total\n",
    "        pct = df[col].isna().mean() * 100 #find the percentage of missing values in that column\n",
    "        if missing_vals != 0: #if there are missing values\n",
    "            print(f\"{col} => {df[col].isnull().sum()},{round(pct,2)}%\") #print the column name, amount of missing values, and percentage of missing values\n",
    "\n",
    "    if total == 0: #if there are no missing values\n",
    "        print(\"no missing values left\") #if there are no missing values left"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ## Train Test Split\n",
    "Here we first implement necessary packets. Then we copy our dataframe and normalize its data.\n",
    "Then we train our model on the training data and test it on the testing data. We use the train_test_split function from sklearn.model_selection.\n",
    "We implement some metrics to evaluate our model and see how well it does. Lastly, print out error metrics (MSE, RMSE, etc.), Accuracy and return our Linear regression object that will be used in the API in later stages.\n",
    "The only algorithm reasonable to use for this amount of data were Linear Regression. Otherwise, it would take too long to run. Other algorithms were used such as Random Forest Regressor,Logarithmic Regression, SVC however these took unreasonable amount of time to run and the latter two could not realized. This is because they only work for classifications and not regressions. The Random Forest Regressor was tested out on only two files and it gave pretty good accuracy but only gave a fraction more in percentage points and took minutes of training."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "def train(df):\n",
    "    from sklearn.model_selection import train_test_split #split data into training and testing sets\n",
    "    from sklearn.metrics import mean_squared_error, r2_score,mean_absolute_error#calculate the mean squared error and r2 score\n",
    "    from sklearn.linear_model import LinearRegression,LogisticRegressionCV,LogisticRegression #import Linear Regression\n",
    "    from sklearn import metrics #import metrics\n",
    "    import matplotlib.pyplot as plt #import matplotlib\n",
    "    import matplotlib as mpl\n",
    "    from sklearn.svm import SVC #import SVC\n",
    "    from sklearn.datasets import make_classification\n",
    "    from sklearn.metrics import RocCurveDisplay, roc_auc_score,roc_curve #import roc curve and auc\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "    copy = df.copy() #copy the dataframe\n",
    "    copy[\"pickup_time\"] = (df[(\"pickup_time\")] - df[(\"pickup_time\")].mean()) / df[(\"pickup_time\")].std() #normalize the pickup time\n",
    "    copy[\"trip_distance\"] = (df[(\"trip_distance\")] - df[(\"trip_distance\")].mean()) / df[(\"trip_distance\")].std() #normalize the trip distance\n",
    "    copy[\"PULocationID\"] = (df[(\"PULocationID\")] - df[(\"PULocationID\")].mean()) / df[(\"PULocationID\")].std() #normalize the PULocationID\n",
    "    copy[\"DOLocationID\"] = (df[(\"DOLocationID\")] - df[(\"DOLocationID\")].mean()) / df[(\"DOLocationID\")].std() #normalize the DOLocationID\n",
    "\n",
    "\n",
    "    #code = diabetes[\"Code\"]\n",
    "    copy[\"trip_time\"] = (df[(\"trip_time\")] - df[(\"trip_time\")].mean()) / df[(\"trip_time\")].std()#normalize the trip time\n",
    "\n",
    "    X = np.asarray(copy[[\"pickup_time\",\"trip_distance\",\"PULocationID\",\"DOLocationID\"]]) #create the X values\n",
    "    Y = np.asarray(copy[\"trip_time\"]) #set the y values to the trip time\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.33,random_state = 1) #split the data into training and testing sets\n",
    "\n",
    "\n",
    "    #Linear Regression\n",
    "    lr = LinearRegression() #create a Linear Regression object\n",
    "\n",
    "    lr.fit(X_train,Y_train) #fit the Linear Regression object to the training data\n",
    "    Y_pred = lr.predict(X_test) #predict the test data\n",
    "    print(\"Linear Regression:\") #print the name of the algorithm\n",
    "    print(\"Accuracy: \",r2_score(Y_test, Y_pred)) #calculate the r2 score Accuracy\n",
    "    print(\"MSE: \",mean_squared_error(Y_test, Y_pred)) #calculate the mean squared error\n",
    "    print(\"MAE: \",mean_absolute_error(Y_test, Y_pred)) #calculate the mean absolute error\n",
    "    MSE = mean_squared_error(Y_test, Y_pred)\n",
    "    RMSE = np.sqrt(MSE) #calculate the root mean squared error\n",
    "    print(\"RMSE: \",RMSE) #print the root mean squared error\n",
    "\n",
    "    return lr #return the Linear Regression object\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ## File iteration\n",
    "In this segment of code we iterate through the files in the directory and create a dataframe for each file. We then clean the dataframe and add it to a list of dataframes."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:12<00:00,  6.41s/it]\n"
     ]
    }
   ],
   "source": [
    "import os #import the os module\n",
    "from tqdm import tqdm #import tqdm to show progress of the loop\n",
    "from IPython.display import clear_output #import clear_output to clear the output of the loop\n",
    "directory = 'data/trips' #set the directory\n",
    "\n",
    "# iterate over files in\n",
    "# that directory\n",
    "full_df = pd.DataFrame() #create a dataframe to store the data\n",
    "for filename in tqdm(os.listdir(directory)): #iterate over the files in the directory\n",
    "    # if type of file is yellow_tripdata_2019-xx.parquet\n",
    "    if filename.startswith('yellow_tripdata_2019-'): #if the file starts with the string 'yellow_tripdata_2019-'\n",
    "        # read the file\n",
    "        df = pd.read_parquet(f\"{directory}/{filename}\") #read the file\n",
    "        df = clean_data(df,1) #clean the data\n",
    "        # append to the full dataframe\n",
    "        full_df = full_df.append(df)\n",
    "    if filename.startswith('green_tripdata_2019-'): #if the file is green_tripdata_2019-xx.parquet\n",
    "        # read the file\n",
    "        df = pd.read_parquet(f\"{directory}/{filename}\") #read the file\n",
    "        df = clean_data(df,2) #clean the data\n",
    "        # append to the full dataframe\n",
    "        full_df = full_df.append(df) #append the dataframe to the full dataframe\n",
    "    clear_output(wait=True) #clear the output of the loop"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "outputs": [
    {
     "data": {
      "text/plain": "         pickup_time  dropoff_time  trip_distance  PULocationID  DOLocationID  \\\n1              616.0         992.0           0.86            97            49   \n2             1631.0        1898.0           0.66            49           189   \n3             2780.0        3894.0           2.68           189            17   \n4             1146.0        2383.0           4.53            82           258   \n5              755.0        1149.0           1.05            49            17   \n...              ...           ...            ...           ...           ...   \n7696609      83400.0       84480.0           9.38           226            42   \n7696610      83820.0       85140.0           6.73           136            51   \n7696611      83640.0       84540.0           5.45            41           136   \n7696613      84480.0       85850.0          12.43            48           213   \n7696614      83460.0       85560.0           9.14           159           246   \n\n         trip_time  \n1            376.0  \n2            267.0  \n3           1114.0  \n4           1237.0  \n5            394.0  \n...            ...  \n7696609     1080.0  \n7696610     1320.0  \n7696611      900.0  \n7696613     1370.0  \n7696614     2100.0  \n\n[8080080 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pickup_time</th>\n      <th>dropoff_time</th>\n      <th>trip_distance</th>\n      <th>PULocationID</th>\n      <th>DOLocationID</th>\n      <th>trip_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>616.0</td>\n      <td>992.0</td>\n      <td>0.86</td>\n      <td>97</td>\n      <td>49</td>\n      <td>376.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1631.0</td>\n      <td>1898.0</td>\n      <td>0.66</td>\n      <td>49</td>\n      <td>189</td>\n      <td>267.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2780.0</td>\n      <td>3894.0</td>\n      <td>2.68</td>\n      <td>189</td>\n      <td>17</td>\n      <td>1114.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1146.0</td>\n      <td>2383.0</td>\n      <td>4.53</td>\n      <td>82</td>\n      <td>258</td>\n      <td>1237.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>755.0</td>\n      <td>1149.0</td>\n      <td>1.05</td>\n      <td>49</td>\n      <td>17</td>\n      <td>394.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7696609</th>\n      <td>83400.0</td>\n      <td>84480.0</td>\n      <td>9.38</td>\n      <td>226</td>\n      <td>42</td>\n      <td>1080.0</td>\n    </tr>\n    <tr>\n      <th>7696610</th>\n      <td>83820.0</td>\n      <td>85140.0</td>\n      <td>6.73</td>\n      <td>136</td>\n      <td>51</td>\n      <td>1320.0</td>\n    </tr>\n    <tr>\n      <th>7696611</th>\n      <td>83640.0</td>\n      <td>84540.0</td>\n      <td>5.45</td>\n      <td>41</td>\n      <td>136</td>\n      <td>900.0</td>\n    </tr>\n    <tr>\n      <th>7696613</th>\n      <td>84480.0</td>\n      <td>85850.0</td>\n      <td>12.43</td>\n      <td>48</td>\n      <td>213</td>\n      <td>1370.0</td>\n    </tr>\n    <tr>\n      <th>7696614</th>\n      <td>83460.0</td>\n      <td>85560.0</td>\n      <td>9.14</td>\n      <td>159</td>\n      <td>246</td>\n      <td>2100.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>8080080 rows × 6 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no missing values left\n"
     ]
    }
   ],
   "source": [
    "display(full_df) #print the full dataframe\n",
    "missing_cols(full_df) #print the missing columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no missing values left\n"
     ]
    },
    {
     "data": {
      "text/plain": "         pickup_time  trip_distance  PULocationID  DOLocationID  trip_time\n1              616.0           0.86            97            49      376.0\n2             1631.0           0.66            49           189      267.0\n3             2780.0           2.68           189            17     1114.0\n4             1146.0           4.53            82           258     1237.0\n5              755.0           1.05            49            17      394.0\n...              ...            ...           ...           ...        ...\n7696609      83400.0           9.38           226            42     1080.0\n7696610      83820.0           6.73           136            51     1320.0\n7696611      83640.0           5.45            41           136      900.0\n7696613      84480.0          12.43            48           213     1370.0\n7696614      83460.0           9.14           159           246     2100.0\n\n[8080080 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pickup_time</th>\n      <th>trip_distance</th>\n      <th>PULocationID</th>\n      <th>DOLocationID</th>\n      <th>trip_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>616.0</td>\n      <td>0.86</td>\n      <td>97</td>\n      <td>49</td>\n      <td>376.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1631.0</td>\n      <td>0.66</td>\n      <td>49</td>\n      <td>189</td>\n      <td>267.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2780.0</td>\n      <td>2.68</td>\n      <td>189</td>\n      <td>17</td>\n      <td>1114.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1146.0</td>\n      <td>4.53</td>\n      <td>82</td>\n      <td>258</td>\n      <td>1237.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>755.0</td>\n      <td>1.05</td>\n      <td>49</td>\n      <td>17</td>\n      <td>394.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7696609</th>\n      <td>83400.0</td>\n      <td>9.38</td>\n      <td>226</td>\n      <td>42</td>\n      <td>1080.0</td>\n    </tr>\n    <tr>\n      <th>7696610</th>\n      <td>83820.0</td>\n      <td>6.73</td>\n      <td>136</td>\n      <td>51</td>\n      <td>1320.0</td>\n    </tr>\n    <tr>\n      <th>7696611</th>\n      <td>83640.0</td>\n      <td>5.45</td>\n      <td>41</td>\n      <td>136</td>\n      <td>900.0</td>\n    </tr>\n    <tr>\n      <th>7696613</th>\n      <td>84480.0</td>\n      <td>12.43</td>\n      <td>48</td>\n      <td>213</td>\n      <td>1370.0</td>\n    </tr>\n    <tr>\n      <th>7696614</th>\n      <td>83460.0</td>\n      <td>9.14</td>\n      <td>159</td>\n      <td>246</td>\n      <td>2100.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>8080080 rows × 5 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_df.drop(\"dropoff_time\", axis=1, inplace=True)\n",
    "full_df.dropna(inplace=True) #drop all the NaN values\n",
    "missing_cols(full_df) #print the missing columns\n",
    "display(full_df) #print the full dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      "Accuracy:  0.635517527275048\n",
      "MSE:  0.36425706392251733\n",
      "MAE:  0.40977587192386017\n",
      "RMSE:  0.6035371272113401\n"
     ]
    }
   ],
   "source": [
    "lr = train(full_df) #train the Linear Regression object"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ## Pickle the Linear Regression object\n",
    "In this segment of code we pickle the Linear Regression object so that we can use it later in our Api."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "outputs": [],
   "source": [
    "import pickle #import pickle to save the Linear Regression object\n",
    "with open('model.pickle', 'wb') as f: #save the Linear Regression object to a file\n",
    "    pickle.dump(lr, f) #save the Linear Regression object to a file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ## Conclusion and reflections\n",
    "In this project we used Linear Regression. This algorithm was used because it was the most efficient and was able to predict the trip time in fairly accurate and in short amount of time. Something that was noticed during the cleaning and training for the months of november and december was that the data was not usable or further cleanable. The data clearly had some issues and brought the accuracy down from a 64% to a low 3% accuracy. Therefore, the data was excluded from the project. As mentioned in the previous section, Linear Regression was the most efficient and accurate algorithm that worked well and was able to predict the trip time in a reasonable amount timeframe. Many models were tried but Linear Regression came out on top."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}